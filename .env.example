# --- Configuration Options --- 
# Choose ONE of the following API configurations:

# Option 1: Use OpenRouter (Recommended for access to various models)
# Get your API key from https://openrouter.ai/keys
# Replace 'YOUR_OPENROUTER_API_KEY_HERE' with your actual key in the .env file.
VITE_OPENROUTER_API_KEY=YOUR_OPENROUTER_API_KEY_HERE

# Option 2: Use a custom OpenAI-compatible endpoint
# Useful for local LLMs (LM Studio, Ollama, etc.) or other cloud providers.
# Uncomment and set BOTH variables below if using this option.
# VITE_OPENAI_API_BASE_URL=http://localhost:1234/v1 # Example: Replace with your server URL
# VITE_OPENAI_API_KEY=YOUR_API_KEY # Example: Often 'none', 'ollama', or a specific key

# --- Optional Settings --- 

# Default Model Selection
# Specify the default model ID to use when the application starts.
# If commented out, the application might use a hardcoded default or prompt for selection.
# Example: VITE_DEFAULT_MODEL=openai/gpt-4o
# Example: VITE_DEFAULT_MODEL=anthropic/claude-3-haiku
# VITE_DEFAULT_MODEL=YOUR_PREFERRED_MODEL_ID